MAX_ITER : 60000
TEST_ITER : 1
TEST_SEED : 10000
resume_iter : 0
device : cpu
neighbor_dispatch : False
onoff_driver : False
dispatch_interval : 10
speed : 10
wait_time : 10
TIME_LEN : 144
grid_num : 36
driver_num : 6000
city_time_start : 0
batch_size : 1000
actor_lr : 0.001
critic_lr : 0.001
train_actor_iters : 1
train_critic_iters : 1
gamma : 0.97
lam : 0.99
max_grad_norm : 10
clip_ratio : 0.2
ent_factor : 0.01
adv_normal : True
clip : True
steps_per_epoch : 144
grad_multi : mean
minibatch_num : 5
parallel_episode : 5
parallel_way : mix
parallel_queue : True
return_scale : False
use_orthogonal : True
use_value_clip : True
use_valuenorm : False
use_huberloss : True
use_lr_anneal : False
use_GAEreturn : True
use_rnn : False
use_GAT : False
use_dropout : False
use_auxi : False
auxi_effi : 0.1
use_fake_auxi : 0
use_regularize : None
regularize_alpha : 0.1
use_neighbor_state : False
adj_rank : 2
merge_method : cat
actor_centralize : False
critic_centralize : False
order_value : False
new_order_entropy : True
update_value : False
order_grid : True
reward_scale : 5
memory_size : 720
FM : False
remove_fake_order : False
team_reward_factor : 5
team_rank : 0
full_share : True
global_share : False
ORR_reward : False
ORR_reward_effi : 1
only_ORR : False
fix_phi : False
policy_num : 4
phi : [0.025088, 0.087006, 0.184027, 0.236112, 0.218559, 0.249208]
log_name : OD36_Batch1000_Gamma0.97_Lambda0.99_Iter1_Ir0.001_Step144_Ent0.01_Minibatch5_Parallel5mix_valueNO_queue_TeamRank0_ORRNO_ActorDecen_CriticDecen_AuxiNo_FakeNewAuxi0__NewEntropy_OrthoInit_ValueClip_Huberloss_GAEreturn
log_dir : logs\synthetic\PPO2
writer_logs : True
